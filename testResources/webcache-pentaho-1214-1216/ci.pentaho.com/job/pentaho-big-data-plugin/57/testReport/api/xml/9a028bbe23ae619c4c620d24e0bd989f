<testResult><duration>89.10299</duration><failCount>0</failCount><passCount>258</passCount><skipCount>0</skipCount><suite><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.191</duration><failedSince>0</failedSince><name>instantiation_null_logging_channel</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>instantiation_null_layout</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0</duration><failedSince>0</failedSince><name>requiresLayout</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>append_basic</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>append_debug</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0</duration><failedSince>0</failedSince><name>append_trace</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0</duration><failedSince>0</failedSince><name>append_off</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>append_error</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.2</duration><name>org.pentaho.di.core.logging.KettleLogChannelAppenderTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:29:27</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>0.202</duration><failedSince>0</failedSince><name>testLoadXml</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>2.375</duration><failedSince>0</failedSince><name>testLoadRep</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testEvaluates</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testIsUnconditional</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>1.022</duration><failedSince>0</failedSince><name>execute_blocking</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>execute_nonblocking</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.AbstractJobEntryTest</className><duration>1.203</duration><failedSince>0</failedSince><name>execute_interrupted</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout></case><duration>4.804</duration><name>org.pentaho.di.job.AbstractJobEntryTest</name><stderr></stderr><stdout>INFO  02-08 12:29:30,634 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:29:30,982 - H2Repo - Created 42 repository tables.
</stdout><timestamp>2012-08-02T16:29:28</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.BlockableJobConfigTest</className><duration>0.021</duration><failedSince>0</failedSince><name>testAddPropertyChangeListener</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.BlockableJobConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testAddPropertyChangeListener_propertyName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.BlockableJobConfigTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testGetterAndSetter</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.BlockableJobConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testClone</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.023</duration><name>org.pentaho.di.job.BlockableJobConfigTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:29:35</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.JobEntryUtilsTest</className><duration>0.027</duration><failedSince>0</failedSince><name>asBoolean</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.JobEntryUtilsTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>asLong</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.JobEntryUtilsTest</className><duration>0.119</duration><failedSince>0</failedSince><name>findLogger</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.JobEntryUtilsTest</className><duration>0.053</duration><failedSince>0</failedSince><name>attachAppenderTo</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.JobEntryUtilsTest</className><duration>0.0</duration><failedSince>0</failedSince><name>removeAppenderFrom</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.2</duration><name>org.pentaho.di.job.JobEntryUtilsTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:29:36</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.LoggingProxyTest</className><duration>0.129</duration><failedSince>0</failedSince><name>wrapSysOut</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>testingINFO  02-08 12:29:38,097 - testing
</stdout></case><duration>0.129</duration><name>org.pentaho.di.job.LoggingProxyTest</name><stderr></stderr><stdout>testingINFO  02-08 12:29:38,097 - testing
</stdout><timestamp>2012-08-02T16:29:37</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.29</duration><failedSince>0</failedSince><name>deleteDirectory</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.0030</duration><failedSince>0</failedSince><name>extract_invalid_archive</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>extract_destination_exists</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.101</duration><failedSince>0</failedSince><name>extractToTemp</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.0</duration><failedSince>0</failedSince><name>extractToTemp_missing_archive</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.0070</duration><failedSince>0</failedSince><name>findFiles_vfs</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.191</duration><failedSince>0</failedSince><name>findFiles_vfs_hdfs</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.072</duration><failedSince>0</failedSince><name>findFiles_hdfs_native</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.071</duration><failedSince>0</failedSince><name>stageForCache</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.034</duration><failedSince>0</failedSince><name>stageForCache_missing_source</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.026</duration><failedSince>0</failedSince><name>stageForCache_destination_no_overwrite</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.062</duration><failedSince>0</failedSince><name>stageForCache_destination_exists</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.028</duration><failedSince>0</failedSince><name>addCachedFilesToClasspath</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.048</duration><failedSince>0</failedSince><name>ispmrInstalledAt</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.0</duration><failedSince>0</failedSince><name>installKettleEnvironment_missing_arguments</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.1</duration><failedSince>0</failedSince><name>installKettleEnvironment</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.167</duration><failedSince>0</failedSince><name>installKettleEnvironment_additional_plugins</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.062</duration><failedSince>0</failedSince><name>stagePluginsForCache</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.113</duration><failedSince>0</failedSince><name>configureWithpmr</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>1.678</duration><failedSince>0</failedSince><name>findPluginFolder</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.013</duration><failedSince>0</failedSince><name>addFilesToClassPath</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</className><duration>0.01</duration><failedSince>0</failedSince><name>addFilesToClassPath_custom_path_separator</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout></case><duration>3.077</duration><name>org.pentaho.di.job.entries.hadooptransjobexecutor.DistributedCacheUtilTest</name><stderr></stderr><stdout>INFO  02-08 12:29:39,616 - Using "/tmp/vfs_cache" as temporary files store.
</stdout><timestamp>2012-08-02T16:29:39</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>0.079</duration><failedSince>0</failedSince><name>getProperty</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>1.214</duration><failedSince>0</failedSince><name>invalidMapperStepNames</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>0.013</duration><failedSince>0</failedSince><name>getProperty_overridden</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>0.013</duration><failedSince>0</failedSince><name>getProperty_default</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>0.877</duration><failedSince>0</failedSince><name>findAdditionalPluginFolders</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</className><duration>0.011</duration><failedSince>0</failedSince><name>useDistributedCache</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout></case><duration>2.207</duration><name>org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest</name><stderr>org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEntryHadoopTransJobExecutorTest.java:79)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAcce...[truncated 9284 chars]...at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more
</stderr><stdout>ERROR 02-08 12:29:47,456 - null - 
Error in mapper configuration

The input step was not specified


ERROR 02-08 12:29:47,458 - null - org.pentaho.di.core.exception.KettleException: 
Error in mapper configuration

The input step was not specified


	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:532)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutorTest.invalidMapperStepNames(JobEn...[truncated 10072 chars]...t org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
Caused by: org.pentaho.di.core.exception.KettleException: 
The output step with name 'Testing' could not be found

	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.verifyTransMeta(JobEntryHadoopTransJobExecutor.java:1113)
	at org.pentaho.di.job.entries.hadooptransjobexecutor.JobEntryHadoopTransJobExecutor.execute(JobEntryHadoopTransJobExecutor.java:530)
	... 23 more

</stdout><timestamp>2012-08-02T16:29:45</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorConfigTest</className><duration>0.014</duration><failedSince>0</failedSince><name>testAddPropertyChangeListener</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorConfigTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testAddPropertyChangeListener_propertyName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testGettersAndSetters</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.015000001</duration><name>org.pentaho.di.job.entries.oozie.OozieJobExecutorConfigTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:29:50</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.023</duration><failedSince>0</failedSince><name>testLoadXml</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.01</duration><failedSince>0</failedSince><name>testLoadXml_customProps</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0030</duration><failedSince>0</failedSince><name>testGetValidationWarnings_emptyConfig</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.384</duration><failedSince>0</failedSince><name>testGetValidationWarnings_invalidOozieUrl</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>testGetValidationWarnings_incompatibleVersions</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetValidationWarnings_CantFindPropertiesFile</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetValidationWarnings_MissingAppPathSetting</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetValidationWarnings_everythingIsGood</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>1.049</duration><failedSince>0</failedSince><name>execute_blocking</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>1.009</duration><failedSince>0</failedSince><name>execute_blocking_FAIL</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testGetProperties</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testGetProperties_VariableizedWorkflowPath</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testGetProperties_fromAdvancedProperties</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout></case><duration>2.4909997</duration><name>org.pentaho.di.job.entries.oozie.OozieJobExecutorJobEntryTest</name><stderr></stderr><stdout>ERROR 02-08 12:29:54,685 - null - nothing to log
</stdout><timestamp>2012-08-02T16:29:51</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.pig.JobEntryPigScriptExecutorTest</className><duration>33.019</duration><failedSince>0</failedSince><name>testRegressionTutorialLocal</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:29:56,876 - pigTest - Start of job execution
INFO  02-08 12:29:56,881 - pigTest - Starting entry [Delete folders]
INFO  02-08 12:29:56,885 - Delete folders - Folder [file:///build/hudson/workspace/pentaho-big-data-plugin/test-res/pig/script1-local-results.txt] already deleted.
INFO  02-08 12:29:56,886 - pigTest - Starting entry [bin]
INFO  02-08 12:29:56,892 - bin - Configuring for Hadoop distribution: generic
INFO  02-08 12:29:56,989 - bin - 2012/08/02 12:29:56 - Connecting to ha...[truncated 37679 chars]...t initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,141 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,141 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,142 - bin - 2012/08/02 12:30:29 - Success!
INFO  02-08 12:30:29,141 - Success!
INFO  02-08 12:30:29,143 - bin - Num successful jobs: 1 num failed jobs: 0
</stdout></case><duration>33.019</duration><name>org.pentaho.di.job.entries.pig.JobEntryPigScriptExecutorTest</name><stderr></stderr><stdout>INFO  02-08 12:29:56,876 - pigTest - Start of job execution
INFO  02-08 12:29:56,881 - pigTest - Starting entry [Delete folders]
INFO  02-08 12:29:56,885 - Delete folders - Folder [file:///build/hudson/workspace/pentaho-big-data-plugin/test-res/pig/script1-local-results.txt] already deleted.
INFO  02-08 12:29:56,886 - pigTest - Starting entry [bin]
INFO  02-08 12:29:56,892 - bin - Configuring for Hadoop distribution: generic
INFO  02-08 12:29:56,989 - bin - 2012/08/02 12:29:56 - Connecting to ha...[truncated 37679 chars]...t initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,141 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,141 - Cannot initialize JVM Metrics with processName=JobTracker, sessionId= - already initialized
INFO  02-08 12:30:29,142 - bin - 2012/08/02 12:30:29 - Success!
INFO  02-08 12:30:29,141 - Success!
INFO  02-08 12:30:29,143 - bin - Num successful jobs: 1 num failed jobs: 0
</stdout><timestamp>2012-08-02T16:29:56</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.AbstractSqoopJobEntryTest</className><duration>0.264</duration><failedSince>0</failedSince><name>execute_invalid_config</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.AbstractSqoopJobEntryTest</className><duration>0.023</duration><failedSince>0</failedSince><name>isValidSqoopConfig_connect</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.AbstractSqoopJobEntryTest</className><duration>0.028</duration><failedSince>0</failedSince><name>isDatabaseSupported</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.315</duration><name>org.pentaho.di.job.entries.sqoop.AbstractSqoopJobEntryTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:30</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.017</duration><failedSince>0</failedSince><name>getValue</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>setName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>setValue</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>isXulEventSource</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testEquals</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testHashCode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiation_null_name</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiation_null_object</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiation_null_setter</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiation_null_getter</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiation_wrong_setter_method_parameters</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>instantiation_wrong_setter_method_parameters2</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>instantiation_wrong_getter_method_return_type</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>instantiation</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>setDisplayName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>setFlag</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.027000003</duration><name>org.pentaho.di.job.entries.sqoop.ArgumentWrapperTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:31</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.018</duration><failedSince>0</failedSince><name>addRemovePropertyChangeListener</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>addRemovePropertyChangeListener_propertyName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.208</duration><failedSince>0</failedSince><name>getAdvancedArgumentsList</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testClone</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0</duration><failedSince>0</failedSince><name>setDatabaseConnectionInformation</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.02</duration><failedSince>0</failedSince><name>numMappers</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0</duration><failedSince>0</failedSince><name>copyConnectionInfoFromAdvanced</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>copyConnectionInfoToAdvanced</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>getModeAsEnum</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.249</duration><name>org.pentaho.di.job.entries.sqoop.SqoopConfigTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:33</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</className><duration>0.058</duration><failedSince>0</failedSince><name>conditionalsForUIInteractions</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</className><duration>0.02</duration><failedSince>0</failedSince><name>getTool</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</className><duration>0.104</duration><failedSince>0</failedSince><name>saveLoadTest_xml</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</className><duration>2.704</duration><failedSince>0</failedSince><name>saveLoadTest_rep</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</className><duration>0.0080</duration><failedSince>0</failedSince><name>getDatabaseMeta</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout></case><duration>2.8939998</duration><name>org.pentaho.di.job.entries.sqoop.SqoopExportJobEntryTest</name><stderr></stderr><stdout>INFO  02-08 12:30:40,748 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:41,053 - H2Repo - Created 42 repository tables.
</stdout><timestamp>2012-08-02T16:30:35</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.162</duration><failedSince>0</failedSince><name>buildSqoopConfig</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.014</duration><failedSince>0</failedSince><name>getToolName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.074</duration><failedSince>0</failedSince><name>saveLoadTest_xml</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>1.958</duration><failedSince>0</failedSince><name>saveLoadTest_rep</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.0070</duration><failedSince>0</failedSince><name>setJobResultFailed</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.017</duration><failedSince>0</failedSince><name>configure</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</className><duration>0.0090</duration><failedSince>0</failedSince><name>attachAndRemoveLoggingAppenders</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout></case><duration>2.241</duration><name>org.pentaho.di.job.entries.sqoop.SqoopImportJobEntryTest</name><stderr></stderr><stdout>INFO  02-08 12:30:44,182 - H2Repo - Starting to create or modify the repository tables...
INFO  02-08 12:30:44,390 - H2Repo - Created 42 repository tables.
</stdout><timestamp>2012-08-02T16:30:42</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.2</duration><failedSince>0</failedSince><name>configureConnectionInformation</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.043</duration><failedSince>0</failedSince><name>configureConnectionInformation_local</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.037</duration><failedSince>0</failedSince><name>getCommandLineArgs_empty</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0090</duration><failedSince>0</failedSince><name>getCommandLineArgs_boolean</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.012</duration><failedSince>0</failedSince><name>getCommandLineArgs_variable_replace</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.01</duration><failedSince>0</failedSince><name>getCommandLineArgs_variable_replace_flag</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>getCommandLineArgs_command_line_string</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>parseCommandLine</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>parseCommandLine_variables</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>parseCommandLine_import_with_delimiters</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0050</duration><failedSince>0</failedSince><name>generateCommandLineString</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0050</duration><failedSince>0</failedSince><name>generateCommandLineString_password</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>generateCommandLineString_variables</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0</duration><failedSince>0</failedSince><name>escapeEscapeSequences</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0050</duration><failedSince>0</failedSince><name>configureFromCommandLine</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.041</duration><failedSince>0</failedSince><name>configureFromCommandLine_no_shorthand_password</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.015</duration><failedSince>0</failedSince><name>configureFromCommandLine_roundtrip</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0050</duration><failedSince>0</failedSince><name>findAllArguments</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><case><age>0</age><className>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</className><duration>0.0</duration><failedSince>0</failedSince><name>findMethod</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout></case><duration>0.39499992</duration><name>org.pentaho.di.job.entries.sqoop.SqoopUtilsTest</name><stderr></stderr><stdout>WARN  02-08 12:30:46,460 - "localhost:54310" is a deprecated filesystem name. Use "hdfs://localhost:54310/" instead.
WARN  02-08 12:30:46,562 - "local" is a deprecated filesystem name. Use "file:///" instead.
sqoop import --connect jdbc:mysql://db.foo.com/corp --table EMPLOYEES --fields-terminated-by '\t' --lines-terminated-by '\n' --optionally-enclosed-by '\"${}' --driver com.microsoft.jdbc.sqlserver.SQLServerDriver
</stdout><timestamp>2012-08-02T16:30:46</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.297</duration><failedSince>0</failedSince><name>testGetLeafFieldsFromSchema</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.03</duration><failedSince>0</failedSince><name>testGetSimpleTopLevelRecordFieldsInteger</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetSimpleTopLevelRecordFieldsString</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.011</duration><failedSince>0</failedSince><name>testConvertToKettleRowManyFields</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0080</duration><failedSince>0</failedSince><name>testGetNonExistentFieldFromTopLevelRecord</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetTopLevelRecordArrayElement</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetTopLevelRecordPositiveIndexOutOfBoundsArrayElement</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetTopLevelMapSimpleRecordField</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testGetTopLevelMapArrayElementFromRecord</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testGetNonExistentTopLevelMapEntry</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0030</duration><failedSince>0</failedSince><name>testUnionHandling</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.avroinput.AvroInputTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>testMapExpansion</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.364</duration><name>org.pentaho.di.trans.steps.avroinput.AvroInputTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:47</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.146</duration><failedSince>0</failedSince><name>testTopLevelObjectStructureNoNestedDocs</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelArrayStructureWithPrimitives</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelArrayStructureWithObjects</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelArrayStructureContainingOneObjectMutipleFields</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelArrayStructureContainingObjectWithArray</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelObjectStructureOneLevelNestedDoc</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testTopLevelObjectStructureTwoLevelNested</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>testModifierUpdateWithMultipleModifiersOfSameType</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testModifierSetComplexArrayGrouping</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>testModifierPushComplexObject</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.15900001</duration><name>org.pentaho.di.trans.steps.mongodboutput.MongoDbOutputTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:49</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.041</duration><failedSince>0</failedSince><name>testSetModeToggleLabel_JobEntryMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testSetModeToggleLabel_UnsupportedJobEntryMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.3</duration><failedSince>0</failedSince><name>testTestSettings_ErrorsFound</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>testTestSettings_NoErrors</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0060</duration><failedSince>0</failedSince><name>testSyncModel_simpleScenario</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0030</duration><failedSince>0</failedSince><name>testSyncModel_advanced_addedProp</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0030</duration><failedSince>0</failedSince><name>testSyncModel_advanced_editProp</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0050</duration><failedSince>0</failedSince><name>testToggleMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>testShouldUseAdvancedProperties_basicMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.36600003</duration><name>org.pentaho.di.ui.job.entries.oozie.OozieJobExecutorControllerTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:50</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.139</duration><failedSince>0</failedSince><name>populateDatabases</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.031</duration><failedSince>0</failedSince><name>getSelectedDatabaseConnection</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.03</duration><failedSince>0</failedSince><name>setSelectedDatabaseConnection</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.027</duration><failedSince>0</failedSince><name>updateDatabaseItemsList</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.025</duration><failedSince>0</failedSince><name>setConnectChanged</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.025</duration><failedSince>0</failedSince><name>setConnectChanged_ignoring_change_events</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.024</duration><failedSince>0</failedSince><name>setUsernameChanged</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.022</duration><failedSince>0</failedSince><name>setUsernameChanged_ignoring_change_events</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.022</duration><failedSince>0</failedSince><name>setPasswordChanged</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.02</duration><failedSince>0</failedSince><name>setPasswordChanged_ignoring_change_events</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.02</duration><failedSince>0</failedSince><name>setModeToggleLabel</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.02</duration><failedSince>0</failedSince><name>createDatabaseItem</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.064</duration><failedSince>0</failedSince><name>updateUiMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.024</duration><failedSince>0</failedSince><name>setUiMode_exception_parsing_command_line</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.042</duration><failedSince>0</failedSince><name>toggleMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.043</duration><failedSince>0</failedSince><name>setUiMode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.031</duration><failedSince>0</failedSince><name>setSelectedAdvancedButton</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</className><duration>0.019</duration><failedSince>0</failedSince><name>syncCommandLineToConfig</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.6280001</duration><name>org.pentaho.di.ui.job.entries.sqoop.AbstractSqoopJobEntryControllerTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:52</timestamp></suite><suite><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</className><duration>0.011</duration><failedSince>0</failedSince><name>equals</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>instantiate_name</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</className><duration>0.0</duration><failedSince>0</failedSince><name>instantiate_displayName</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testHashCode</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</className><duration>0.0</duration><failedSince>0</failedSince><name>testToString</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.012</duration><name>org.pentaho.di.ui.job.entries.sqoop.DatabaseItemTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:54</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.jobconf.HadoopConfigurerFactoryTest</className><duration>0.013</duration><failedSince>0</failedSince><name>getAvailableConfigurers</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.jobconf.HadoopConfigurerFactoryTest</className><duration>0.0</duration><failedSince>0</failedSince><name>getConfigurer</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.jobconf.HadoopConfigurerFactoryTest</className><duration>0.0</duration><failedSince>0</failedSince><name>getConfigurer_unknown</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.jobconf.HadoopConfigurerFactoryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>locateConfigurer</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.014</duration><name>org.pentaho.hadoop.jobconf.HadoopConfigurerFactoryTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:56</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</className><duration>0.015</duration><failedSince>0</failedSince><name>isKettleType</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</className><duration>0.116</duration><failedSince>0</failedSince><name>getWritableForKettleType</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</className><duration>0.016</duration><failedSince>0</failedSince><name>getConverter</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>getJavaClass</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>getConverter_with_ValueMetaInterface</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.149</duration><name>org.pentaho.hadoop.mapreduce.converter.TypeConverterFactoryTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:30:58</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.BytesWritableToByteArrayConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.BytesWritableToByteArrayConverterTest</className><duration>0.09</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.104</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.BytesWritableToByteArrayConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:00</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToDoubleConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToDoubleConverterTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.016</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToDoubleConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:01</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToLongConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToLongConverterTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.016</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.DoubleWritableToLongConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:02</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.ImmutableBytesWritablePassThroughConverterTest</className><duration>0.021</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.021</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.ImmutableBytesWritablePassThroughConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:03</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.IntWritableToLongConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.IntWritableToLongConverterTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.015000001</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.IntWritableToLongConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:05</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBooleanWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBooleanWritableConverterTest</className><duration>0.123</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.13700001</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBooleanWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:06</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBytesWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBytesWritableConverterTest</className><duration>0.125</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.139</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToBytesWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:07</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToDoubleWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToDoubleWritableConverterTest</className><duration>0.113</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.127</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToDoubleWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:08</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToIntWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToIntWritableConverterTest</className><duration>0.116</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.13</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToIntWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:10</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToLongWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToLongWritableConverterTest</className><duration>0.114</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.128</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToLongWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:11</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToTextConverterTest</className><duration>0.015</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToTextConverterTest</className><duration>0.126</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.141</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.KettleTypeToTextConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:12</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToLongConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToLongConverterTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.016</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToLongConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:13</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToTextConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToTextConverterTest</className><duration>0.084</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.098</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.LongWritableToTextConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:17</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.NullConverterTest</className><duration>0.012</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.NullConverterTest</className><duration>0.0010</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.013</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.NullConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:18</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.NullWritableConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.NullWritableConverterTest</className><duration>0.0020</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.016</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.NullWritableConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:19</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.ObjectToStringConverterTest</className><duration>0.011</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.ObjectToStringConverterTest</className><duration>0.0040</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.015000001</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.ObjectToStringConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:21</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.ResultPassThroughConverterTest</className><duration>0.017</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.017</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.ResultPassThroughConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:22</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToIntegerConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToIntegerConverterTest</className><duration>0.122</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.136</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.TextToIntegerConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:23</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToLongConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToLongConverterTest</className><duration>0.118</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.132</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.TextToLongConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:24</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToStringConverterTest</className><duration>0.014</duration><failedSince>0</failedSince><name>canConvert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.converter.converters.TextToStringConverterTest</className><duration>0.083</duration><failedSince>0</failedSince><name>convert</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.096999995</duration><name>org.pentaho.hadoop.mapreduce.converter.converters.TextToStringConverterTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:25</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.136</duration><failedSince>0</failedSince><name>getPluginDirProperty</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.014</duration><failedSince>0</failedSince><name>getPluginDirProperty_explicitly_set</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.014</duration><failedSince>0</failedSince><name>getKettleHomeProperty</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.013</duration><failedSince>0</failedSince><name>getKettleHomeProperty_explicitly_set</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.538</duration><failedSince>0</failedSince><name>createTrans_normalEngine</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MRUtilTest</className><duration>0.027</duration><failedSince>0</failedSince><name>createTrans_singleThreaded</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.742</duration><name>org.pentaho.hadoop.mapreduce.test.MRUtilTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:31:26</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.788</duration><failedSince>0</failedSince><name>testMapperBadInjectorFields</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.173</duration><failedSince>0</failedSince><name>testMapperBadOutputFields</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.058</duration><failedSince>0</failedSince><name>testMapperNoInjectorStep</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.05</duration><failedSince>0</failedSince><name>testMapperNoOutputStep</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.047</duration><failedSince>0</failedSince><name>testReducerBadInjectorFields</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.023</duration><failedSince>0</failedSince><name>testReducerBadOutputFields</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.041</duration><failedSince>0</failedSince><name>testReducerNoInjectorStep</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.039</duration><failedSince>0</failedSince><name>testReducerNoOutputStep</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>29.877</duration><failedSince>0</failedSince><name>testMapRunnable_wordCount</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.228</duration><failedSince>0</failedSince><name>testMapper_null_output_value</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.346</duration><failedSince>0</failedSince><name>testCombiner_null_output_value</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.05</duration><failedSince>0</failedSince><name>testReducer_null_output_value</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.203</duration><failedSince>0</failedSince><name>testLogChannelLeaking_mapper</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.038</duration><failedSince>0</failedSince><name>testCombiner_single_threaded_wordcount</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.014</duration><failedSince>0</failedSince><name>testCombinerBadOutputFields</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.212</duration><failedSince>0</failedSince><name>testLogChannelLeaking_combiner</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.179</duration><failedSince>0</failedSince><name>testLogChannelLeaking_reducer</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.08</duration><failedSince>0</failedSince><name>testMapReduce_InputOutput</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.052</duration><failedSince>0</failedSince><name>testCombinerOutputClasses</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</className><duration>0.062</duration><failedSince>0</failedSince><name>testReducerOutputClasses</name><skipped>false</skipped><status>PASSED</status><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout></case><duration>32.56</duration><name>org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest</name><stderr>org.pentaho.di.core.exception.KettleException: 
key or value is not defined in transformation injector step

	at org.pentaho.hadoop.mapreduce.PentahoMapRunnable.run(PentahoMapRunnable.java:439)
	at org.pentaho.hadoop.mapreduce.test.MapperAndReducerTest.testMapperBadInjectorFields(MapperAndReducerTest.java:71)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:39)
	at sun.reflect.DelegatingMethodAccessorImp...[truncated 14727 chars]...	at org.junit.internal.runners.statements.RunAfters.evaluate(RunAfters.java:31)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:220)
	at junit.framework.JUnit4TestAdapter.run(JUnit4TestAdapter.java:39)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.run(JUnitTestRunner.java:420)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.launch(JUnitTestRunner.java:911)
	at org.apache.tools.ant.taskdefs.optional.junit.JUnitTestRunner.main(JUnitTestRunner.java:768)
</stderr><stdout>Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,421 - bad-injector-fields - Dispatching started for transformation [bad-injector-fields]
Could not retrieve the log level from the job configuration.  logLevel will not be set.
INFO  02-08 12:31:29,513 - bad-output-fields - Dispatching started for transformation [bad-output-fields]
ERROR 02-08 12:31:29,554 - Output - Unexpected error
ERROR 02-08 12:31:29,554 - Output - java.lang.RuntimeEx...[truncated 37237 chars]...patching started for transformation [mr-input-output]
INFO  02-08 12:32:05,365 - Injector - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,367 - Select values - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
INFO  02-08 12:32:05,369 - Output - Finished processing (I=0, O=0, R=3, W=3, U=0, E=0)
Could not retrieve the log level from the job configuration.  logLevel will not be set.
Could not retrieve the log level from the job configuration.  logLevel will not be set.
</stdout><timestamp>2012-08-02T16:31:28</timestamp></suite><suite><case><age>0</age><className>org.pentaho.hadoop.mapreduce.test.OrdinalExtractionTest</className><duration>0.185</duration><failedSince>0</failedSince><name>test1</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.185</duration><name>org.pentaho.hadoop.mapreduce.test.OrdinalExtractionTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:32:06</timestamp></suite><suite><case><age>0</age><className>org.pentaho.trans.steps.hadoopfileoutput.HadoopFileOutputTest</className><duration>0.124</duration><failedSince>0</failedSince><name>testFileAsCommandOption</name><skipped>false</skipped><status>PASSED</status><stderr></stderr><stdout></stdout></case><duration>0.124</duration><name>org.pentaho.trans.steps.hadoopfileoutput.HadoopFileOutputTest</name><stderr></stderr><stdout></stdout><timestamp>2012-08-02T16:32:08</timestamp></suite></testResult>